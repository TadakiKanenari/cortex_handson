# =========================================================
# Snowflake Cortex Handson ã‚·ãƒŠãƒªã‚ª#2
# AIã‚’ç”¨ã„ãŸé¡§å®¢ã®å£°åˆ†æã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
# Step1: ãƒ‡ãƒ¼ã‚¿æº–å‚™ãƒšãƒ¼ã‚¸
# =========================================================
# æ¦‚è¦: æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèªã¨ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†
# ä½¿ç”¨ã™ã‚‹æ©Ÿèƒ½: SPLIT_TEXT_RECURSIVE_CHARACTER, TRANSLATE, SENTIMENT, EMBED_TEXT_1024
# =========================================================
# Created by Tsubasa Kanno @Snowflake
# æœ€çµ‚æ›´æ–°: 2025/06/16
# =========================================================

import streamlit as st
import pandas as pd
import json
import plotly.express as px
import plotly.graph_objects as go
from snowflake.snowpark.context import get_active_session
from snowflake.snowpark.functions import col, lit
from datetime import datetime
import time
import sys
import os

# è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ ï¼ˆtable_utilsã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹ãŸã‚ï¼‰
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from table_utils import resolve_table_name, check_table_with_fallback, get_table_count_with_fallback

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(layout="wide")

# Snowflakeã‚»ãƒƒã‚·ãƒ§ãƒ³å–å¾—
@st.cache_resource
def get_snowflake_session():
    return get_active_session()

session = get_snowflake_session()

# =========================================================
# å®šæ•°è¨­å®š
# =========================================================
# åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«é¸æŠè‚¢
EMBEDDING_MODELS = [
    "multilingual-e5-large",
    "voyage-multilingual-2", 
    "snowflake-arctic-embed-l-v2.0",
    "nv-embed-qa-4"
]

# session_stateã§é¸æŠã•ã‚ŒãŸembeddingãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–
if 'selected_embedding_model' not in st.session_state:
    st.session_state.selected_embedding_model = EMBEDDING_MODELS[0]

# =========================================================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# =========================================================

# Part1ã‚¹ã‚­ãƒƒãƒ—æ™‚ã®è‡ªå‹•SWAPå¯¾è±¡ãƒ†ãƒ¼ãƒ–ãƒ«
SWAP_TARGET_TABLES = [
    "PRODUCT_MASTER",
    "PRODUCT_MASTER_EMBED",
    "EC_DATA_WITH_PRODUCT_MASTER",
    "RETAIL_DATA_WITH_PRODUCT_MASTER"
]

def check_table_exists(table_name: str) -> bool:
    """ãƒ†ãƒ¼ãƒ–ãƒ«ã®å­˜åœ¨ç¢ºèªï¼ˆè¤‡æ•°ã®æ–¹æ³•ã§ç¢ºèªï¼‰"""
    try:
        # æ–¹æ³•1: SHOW TABLESã‚’ä½¿ç”¨ã—ã¦ãƒ†ãƒ¼ãƒ–ãƒ«ã®å­˜åœ¨ã‚’ç¢ºèª
        result = session.sql(f"SHOW TABLES LIKE '{table_name}'").collect()
        if len(result) > 0:
            return True
    except:
        pass
    
    try:
        # æ–¹æ³•2: ç°¡å˜ãªSELECTã‚¯ã‚¨ãƒªã‚’è©¦è¡Œ
        session.sql(f"SELECT 1 FROM {table_name} LIMIT 1").collect()
        return True
    except:
        pass
    
    try:
        # æ–¹æ³•3: DESCRIBE TABLEã‚’è©¦è¡Œ
        session.sql(f"DESCRIBE TABLE {table_name}").collect()
        return True
    except:
        pass
    
    return False

def auto_swap_prebuilt_tables():
    """
    Part1ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ãŸå ´åˆã€ç©ºã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ¤œçŸ¥ã—ã¦_PREBUILTãƒ†ãƒ¼ãƒ–ãƒ«ã¨SWAPã™ã‚‹
    """
    swapped = []
    for table_name in SWAP_TARGET_TABLES:
        try:
            if not check_table_exists(table_name):
                continue
            result = session.sql(f"SELECT COUNT(*) as cnt FROM {table_name}").collect()
            count = result[0]['CNT']
            if count == 0:
                prebuilt_table = f"{table_name}_PREBUILT"
                if check_table_exists(prebuilt_table):
                    prebuilt_result = session.sql(f"SELECT COUNT(*) as cnt FROM {prebuilt_table}").collect()
                    if prebuilt_result[0]['CNT'] > 0:
                        session.sql(f"ALTER TABLE {table_name} SWAP WITH {prebuilt_table}").collect()
                        swapped.append(table_name)
        except:
            pass
    return swapped

# ã‚¢ãƒ—ãƒªèµ·å‹•æ™‚ã«è‡ªå‹•SWAPå®Ÿè¡Œï¼ˆsession_stateã§1å›ã®ã¿ï¼‰
if 'auto_swap_executed' not in st.session_state:
    swapped_tables = auto_swap_prebuilt_tables()
    st.session_state.auto_swap_executed = True
    if swapped_tables:
        st.session_state.swapped_tables = swapped_tables

def get_table_count(table_name: str) -> int:
    """ãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ã‚’å–å¾—"""
    try:
        result = session.sql(f"SELECT COUNT(*) as count FROM {table_name}").collect()
        return result[0]['COUNT']
    except:
        return 0

def process_reviews(embedding_model: str, limit: int = 10):
    """ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã‚’å®Ÿè¡Œ"""
    # æœªå‡¦ç†ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å–å¾—
    limit_clause = f"LIMIT {limit}" if limit else ""
    reviews = session.sql(f"""
        SELECT r.*
        FROM CUSTOMER_REVIEWS r
        LEFT JOIN CUSTOMER_ANALYSIS a ON r.review_id = a.review_id
        WHERE a.review_id IS NULL
        {limit_clause}
    """).collect()
    
    if not reviews:
        st.info("å‡¦ç†ãŒå¿…è¦ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    progress_bar = st.progress(0)
    progress_text = st.empty()
    
    for i, review in enumerate(reviews):
        # é€²æ—è¡¨ç¤º
        progress = (i + 1) / len(reviews)
        progress_bar.progress(progress)
        progress_text.text(f"å‡¦ç†ä¸­: {i + 1}/{len(reviews)} ä»¶")
        
        # ãƒ¬ãƒ“ãƒ¥ãƒ¼å…¨ä½“ã®æ„Ÿæƒ…åˆ†æï¼ˆè‹±èªç¿»è¨³ã—ã¦ã‹ã‚‰å®Ÿè¡Œï¼‰
        translated_text = session.sql("""
            SELECT SNOWFLAKE.CORTEX.ã€â˜…â˜…â˜…ä¿®æ­£å¯¾è±¡â˜…â˜…â˜…ã€(?, '', 'en') as translated
        """, params=[review['REVIEW_TEXT']]).collect()[0]['TRANSLATED']
        
        sentiment_score = session.sql("""
            SELECT SNOWFLAKE.CORTEX.ã€â˜…â˜…â˜…ä¿®æ­£å¯¾è±¡â˜…â˜…â˜…ã€(?) as score
        """, params=[translated_text]).collect()[0]['SCORE']
        
        # ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
        chunks = session.sql("""
            SELECT t.value as chunk
            FROM (
                SELECT SNOWFLAKE.CORTEX.ã€â˜…â˜…â˜…ä¿®æ­£å¯¾è±¡â˜…â˜…â˜…ã€(
                    ?, 'none', 300, 30
                ) as split_result
            ),
            LATERAL FLATTEN(input => split_result) t
        """, params=[review['REVIEW_TEXT']]).collect()
        
        # å„ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†ã—ã¦CUSTOMER_ANALYSISã«æŒ¿å…¥
        for chunk in chunks:
            session.sql("""
                INSERT INTO CUSTOMER_ANALYSIS (
                    review_id, product_id, customer_id, rating, review_text,
                    review_date, purchase_channel, helpful_votes,
                    chunked_text, embedding, sentiment_score
                )
                SELECT 
                    ?, ?, ?, ?, ?, ?, ?, ?, ?,
                    SNOWFLAKE.CORTEX.ã€â˜…â˜…â˜…ä¿®æ­£å¯¾è±¡â˜…â˜…â˜…ã€(?, ?),
                    ?
            """, params=[
                review['REVIEW_ID'], review['PRODUCT_ID'], review['CUSTOMER_ID'],
                review['RATING'], review['REVIEW_TEXT'], review['REVIEW_DATE'],
                review['PURCHASE_CHANNEL'], review['HELPFUL_VOTES'],
                chunk['CHUNK'], embedding_model, chunk['CHUNK'], sentiment_score
            ]).collect()
    
    progress_text.text(f"å®Œäº†: {len(reviews)} ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å‡¦ç†ã—ã¾ã—ãŸ")

# =========================================================
# ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«
# =========================================================
st.title("ğŸ“Š Step1: ãƒ‡ãƒ¼ã‚¿æº–å‚™")
st.header("æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèªã¨ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†")

# =========================================================
# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
# =========================================================
st.sidebar.header("âš™ï¸ è¨­å®š")

# åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®é¸æŠ
selected_embedding_model = st.sidebar.selectbox(
    "åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ:",
    EMBEDDING_MODELS,
    index=EMBEDDING_MODELS.index(st.session_state.selected_embedding_model),
    key="embedding_model_selectbox",
    help="ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã«ä½¿ç”¨ã™ã‚‹åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„"
)

# é¸æŠãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã€session_stateã‚’æ›´æ–°
if selected_embedding_model != st.session_state.selected_embedding_model:
    st.session_state.selected_embedding_model = selected_embedding_model

st.sidebar.info(f"""
**é¸æŠä¸­ã®ãƒ¢ãƒ‡ãƒ«:**
- åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«: `{st.session_state.selected_embedding_model}`

ã“ã®ãƒ¢ãƒ‡ãƒ«ãŒãƒ†ã‚­ã‚¹ãƒˆã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚
""")

# =========================================================
# ãƒ‡ãƒ¼ã‚¿ä¿®å¾©æ©Ÿèƒ½ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼‰
# =========================================================
st.sidebar.markdown("---")
st.sidebar.header("ğŸ”§ ãƒ‡ãƒ¼ã‚¿ä¿®å¾©")
st.sidebar.markdown("""
Part1ã‚’å®Ÿè¡Œã›ãšã«Part2ã‹ã‚‰é–‹å§‹ã™ã‚‹å ´åˆã€ã¾ãŸã¯
Part1ãŒä¸­é€”åŠç«¯ãªçŠ¶æ…‹ã®å ´åˆã¯ã€ä»¥ä¸‹ã®ãƒœã‚¿ãƒ³ã§
å®Œæˆãƒ‡ãƒ¼ã‚¿ã«ç½®ãæ›ãˆã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
""")

def manual_swap_prebuilt_tables():
    """æ‰‹å‹•ã§PREBUILTãƒ†ãƒ¼ãƒ–ãƒ«ã¨SWAP"""
    swapped = []
    errors = []
    for table_name in SWAP_TARGET_TABLES:
        try:
            prebuilt_table = f"{table_name}_PREBUILT"
            if check_table_exists(table_name) and check_table_exists(prebuilt_table):
                session.sql(f"ALTER TABLE {table_name} SWAP WITH {prebuilt_table}").collect()
                swapped.append(table_name)
        except Exception as e:
            errors.append(f"{table_name}: {str(e)}")
    return swapped, errors

if st.sidebar.button("ğŸ”„ å®Œæˆãƒ‡ãƒ¼ã‚¿ã«ç½®æ›", help="Part1ã®æˆæœç‰©ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å®Œæˆãƒ‡ãƒ¼ã‚¿ã«ç½®ãæ›ãˆã¾ã™"):
    with st.sidebar:
        with st.spinner("ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç½®æ›ä¸­..."):
            swapped, errors = manual_swap_prebuilt_tables()
        
        if swapped:
            st.success(f"âœ… {len(swapped)}å€‹ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç½®æ›ã—ã¾ã—ãŸ")
            for t in swapped:
                st.write(f"  - {t}")
            st.rerun()
        elif errors:
            st.error("âŒ ç½®æ›ã«å¤±æ•—ã—ã¾ã—ãŸ")
            for e in errors:
                st.write(f"  - {e}")
        else:
            st.info("ç½®æ›å¯¾è±¡ã®ãƒ†ãƒ¼ãƒ–ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")

st.markdown("---")

# =========================================================
# ã‚»ã‚¯ã‚·ãƒ§ãƒ³1: æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
# =========================================================
st.subheader("ğŸ—„ï¸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³1: æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª")
st.markdown("ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—ã§ä½¿ç”¨ã™ã‚‹æ—¢å­˜ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç¢ºèªã—ã¾ã—ã‚‡ã†ã€‚")

# æ—¢å­˜ãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒªã‚¹ãƒˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯¾å¿œãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å«ã‚€ï¼‰
existing_tables = {
    "RETAIL_DATA_WITH_PRODUCT_MASTER": "ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°æ¸ˆã¿åº—èˆ—ãƒ‡ãƒ¼ã‚¿",
    "EC_DATA_WITH_PRODUCT_MASTER": "ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°æ¸ˆã¿ECãƒ‡ãƒ¼ã‚¿", 
    "CUSTOMER_REVIEWS": "é¡§å®¢ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿",
    "SNOW_RETAIL_DOCUMENTS": "ç¤¾å†…ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ"
}

tab1, tab2 = st.tabs(["ğŸ“‹ ãƒ†ãƒ¼ãƒ–ãƒ«ç¢ºèª", "ğŸ” ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«"])

with tab1:
    st.markdown("#### ğŸ“‹ æ—¢å­˜ãƒ†ãƒ¼ãƒ–ãƒ«ã®çŠ¶æ³ç¢ºèª")
    
    # ãƒ†ãƒ¼ãƒ–ãƒ«å­˜åœ¨ç¢ºèªï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯¾å¿œ - é€éçš„ï¼‰
    table_status = {}
    
    for table_name, description in existing_tables.items():
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯¾å¿œã®ãƒ†ãƒ¼ãƒ–ãƒ«ç¢ºèª
        info = check_table_with_fallback(table_name, session)
        count, actual_table, is_fallback = get_table_count_with_fallback(table_name, session)
        
        table_status[table_name] = {
            "exists": info["exists"], 
            "count": count, 
            "description": description,
            "actual_table": actual_table,
            "is_fallback": is_fallback
        }
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§ã‚‚é€šå¸¸ã¨åŒã˜è¡¨ç¤º
        if info["exists"]:
            st.write(f"âœ… **{table_name}** ({description}): {count:,}ä»¶")
        else:
            st.write(f"âŒ **{table_name}** ({description}): æœªä½œæˆ")
    
    # å…¨ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    all_tables_exist = all(status["exists"] for status in table_status.values())
    
    if all_tables_exist:
        st.success("âœ… å…¨ã¦ã®å¿…è¦ãªãƒ†ãƒ¼ãƒ–ãƒ«ãŒç¢ºèªã•ã‚Œã¾ã—ãŸï¼")
    else:
        st.warning("âš ï¸ ä¸€éƒ¨ã®ãƒ†ãƒ¼ãƒ–ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—ã®å‰æº–å‚™ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

with tab2:
    st.markdown("#### ğŸ” ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«ã®ç¢ºèª")
    
    # ãƒ†ãƒ¼ãƒ–ãƒ«é¸æŠ
    available_tables = [name for name, status in table_status.items() if status["exists"]]
    
    if available_tables:
        selected_table = st.selectbox(
            "ç¢ºèªã™ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’é¸æŠ:",
            available_tables,
            format_func=lambda x: f"{x} ({existing_tables[x]})"
        )
        
        @st.fragment
        def show_sample_data():
            """ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿è¡¨ç¤ºã®ãƒ•ãƒ©ã‚°ãƒ¡ãƒ³ãƒˆ"""
            if st.button("ğŸ“„ ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º"):
                try:
                    sample_data = session.sql(f"SELECT * FROM {selected_table} LIMIT 5").collect()
                    if sample_data:
                        df_sample = pd.DataFrame([row.as_dict() for row in sample_data])
                        st.dataframe(df_sample, use_container_width=True)
                    else:
                        st.info("ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                except Exception as e:
                    st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        show_sample_data()
    else:
        st.warning("åˆ©ç”¨å¯èƒ½ãªãƒ†ãƒ¼ãƒ–ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

# =========================================================
# ã‚»ã‚¯ã‚·ãƒ§ãƒ³2: ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†
# =========================================================
st.markdown("---")
st.subheader("ğŸ”„ ã‚»ã‚¯ã‚·ãƒ§ãƒ³2: ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†")
st.markdown("é¡§å®¢ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦Cortex AIæ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ãŸå‰å‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")

if not check_table_exists("CUSTOMER_REVIEWS"):
    st.error("CUSTOMER_REVIEWSãƒ†ãƒ¼ãƒ–ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å‰æº–å‚™ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
else:
    # å‰å‡¦ç†ãƒ†ãƒ¼ãƒ–ãƒ«ã®ç¢ºèª/ä½œæˆ
    st.info("""
    **å‰å‡¦ç†ã§å®Ÿè¡Œã•ã‚Œã‚‹å‡¦ç†ï¼š**
    1. **ç¿»è¨³ãƒ»æ„Ÿæƒ…åˆ†æ**: ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆå…¨ä½“ã‚’è‹±èªã«ç¿»è¨³ã—ã€æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ã‚’ç®—å‡ºï¼ˆTRANSLATE, SENTIMENTï¼‰
    2. **ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²**: ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ï¼ˆSPLIT_TEXT_RECURSIVE_CHARACTERï¼‰
    3. **ãƒ™ã‚¯ãƒˆãƒ«åŒ–**: åˆ†å‰²ã•ã‚ŒãŸãƒãƒ£ãƒ³ã‚¯ãƒ†ã‚­ã‚¹ãƒˆã‚’1024æ¬¡å…ƒã®ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ï¼ˆEMBED_TEXT_1024ï¼‰
    """)
    
    # å‰å‡¦ç†ãƒ†ãƒ¼ãƒ–ãƒ«ã®å­˜åœ¨ç¢ºèª
    analysis_table_exists = check_table_exists("CUSTOMER_ANALYSIS")
    
    if not analysis_table_exists:
        st.warning("å‰å‡¦ç†ç”¨ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆCUSTOMER_ANALYSISï¼‰ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
        if st.button("ğŸ”§ å‰å‡¦ç†ç”¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆ", type="primary"):
            with st.spinner("å‰å‡¦ç†ç”¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆä¸­..."):
                try:
                    session.sql("""
                    CREATE TABLE IF NOT EXISTS CUSTOMER_ANALYSIS (
                        analysis_id NUMBER AUTOINCREMENT,
                        review_id VARCHAR(20),
                        product_id VARCHAR(10),
                        customer_id VARCHAR(10),
                        rating NUMBER(2,1),
                        review_text TEXT,
                        review_date TIMESTAMP_NTZ,
                        purchase_channel VARCHAR(20),
                        helpful_votes NUMBER(5),
                        chunked_text TEXT,
                        embedding VECTOR(FLOAT, 1024),
                        sentiment_score FLOAT,
                        updated_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP()
                    )
                    """).collect()
                    st.success("âœ… å‰å‡¦ç†ç”¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸï¼")
                    st.rerun()
                        
                except Exception as e:
                    st.error(f"âŒ ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
    else:
        # å‰å‡¦ç†ç”¨ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ¨ªã„ã£ã±ã„ã«è¡¨ç¤º
        st.success("âœ… å‰å‡¦ç†ç”¨ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆCUSTOMER_ANALYSISï¼‰ãŒå­˜åœ¨ã—ã¾ã™ã€‚")
        
        col1, col2 = st.columns(2)
        
        with col1:
            processed_count = get_table_count("CUSTOMER_ANALYSIS")
            st.metric("å‡¦ç†æ¸ˆã¿ãƒãƒ£ãƒ³ã‚¯æ•°", f"{processed_count:,}ä»¶")
        
        with col2:
            # å‰å‡¦ç†å®Ÿè¡Œãƒœã‚¿ãƒ³
            # æœªå‡¦ç†ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°ã®ç¢ºèª
            try:
                unprocessed_count = session.sql("""
                    SELECT COUNT(*) as count
                    FROM CUSTOMER_REVIEWS r
                    LEFT JOIN CUSTOMER_ANALYSIS a ON r.review_id = a.review_id
                    WHERE a.review_id IS NULL
                """).collect()[0]['COUNT']
                
                st.metric("æœªå‡¦ç†ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°", f"{unprocessed_count:,}ä»¶")
                
                if unprocessed_count > 0:
                    # 10ä»¶å‡¦ç†ãƒœã‚¿ãƒ³
                    if st.button("ğŸ§ª 10ä»¶ãšã¤å‡¦ç†", type="secondary", use_container_width=True):
                        with st.spinner("ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’å‰å‡¦ç†ä¸­ï¼ˆ10ä»¶ï¼‰..."):
                            try:
                                process_reviews(st.session_state.selected_embedding_model, limit=10)
                                st.success("âœ… 10ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                                st.rerun()
                            except Exception as e:
                                st.error(f"âŒ å‰å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
                    
                    # å…¨ä»¶å‡¦ç†ãƒœã‚¿ãƒ³
                    if st.button("ğŸš€ å…¨ä»¶å‡¦ç†", type="primary", use_container_width=True):
                        with st.spinner("ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’å‰å‡¦ç†ä¸­ï¼ˆå…¨ä»¶ï¼‰..."):
                            try:
                                process_reviews(st.session_state.selected_embedding_model, limit=None)
                                st.success("âœ… å…¨ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                                st.rerun()
                            except Exception as e:
                                st.error(f"âŒ å‰å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
                else:
                    st.info("ã™ã¹ã¦ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒå‡¦ç†æ¸ˆã¿ã§ã™ã€‚")
                    
            except Exception as e:
                st.error(f"âŒ å‰å‡¦ç†çŠ¶æ³ã®ç¢ºèªã§ã‚¨ãƒ©ãƒ¼: {str(e)}")

# =========================================================
# ã‚»ã‚¯ã‚·ãƒ§ãƒ³3: å‰å‡¦ç†çµæœã®ç¢ºèª
# =========================================================
if check_table_exists("CUSTOMER_ANALYSIS"):
    st.markdown("---")
    st.subheader("ğŸ“ˆ ã‚»ã‚¯ã‚·ãƒ§ãƒ³3: å‰å‡¦ç†çµæœã®ç¢ºèª")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # æ„Ÿæƒ…ã‚¹ã‚³ã‚¢åˆ†å¸ƒï¼ˆãƒ¬ãƒ“ãƒ¥ãƒ¼å˜ä½ã§è¡¨ç¤ºï¼‰
        try:
            sentiment_stats = session.sql("""
                SELECT 
                    sentiment_score,
                    COUNT(DISTINCT review_id) as review_count
                FROM CUSTOMER_ANALYSIS
                GROUP BY sentiment_score
                ORDER BY sentiment_score
            """).collect()
            
            if sentiment_stats:
                sentiment_df = pd.DataFrame([row.as_dict() for row in sentiment_stats])
                fig = px.histogram(sentiment_df, x='SENTIMENT_SCORE', y='REVIEW_COUNT',
                                 title='æ„Ÿæƒ…ã‚¹ã‚³ã‚¢åˆ†å¸ƒï¼ˆãƒ¬ãƒ“ãƒ¥ãƒ¼å˜ä½ï¼‰', nbins=20,
                                 labels={'REVIEW_COUNT': 'ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°', 'SENTIMENT_SCORE': 'æ„Ÿæƒ…ã‚¹ã‚³ã‚¢'})
                st.plotly_chart(fig, use_container_width=True)
        except:
            st.info("æ„Ÿæƒ…ã‚¹ã‚³ã‚¢åˆ†å¸ƒãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
    
    with col2:
        # å‡¦ç†çµ±è¨ˆ
        try:
            stats = session.sql("""
                SELECT 
                    COUNT(DISTINCT review_id) as unique_reviews,
                    COUNT(*) as total_chunks,
                    AVG(sentiment_score) as avg_sentiment,
                    MIN(sentiment_score) as min_sentiment,
                    MAX(sentiment_score) as max_sentiment
                FROM CUSTOMER_ANALYSIS
            """).collect()[0]
            
            st.metric("å‡¦ç†æ¸ˆã¿ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°", f"{stats['UNIQUE_REVIEWS']:,}ä»¶")
            st.metric("ç·ãƒãƒ£ãƒ³ã‚¯æ•°", f"{stats['TOTAL_CHUNKS']:,}ä»¶")
            st.metric("å¹³å‡æ„Ÿæƒ…ã‚¹ã‚³ã‚¢", f"{stats['AVG_SENTIMENT']:.3f}")
            
        except:
            st.info("å‡¦ç†çµ±è¨ˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

# =========================================================
# æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—
# =========================================================
st.markdown("---")
st.subheader("ğŸ¯ Step1 å®Œäº†ï¼")
st.success("""
âœ… **ãƒ‡ãƒ¼ã‚¿æº–å‚™ã¨ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã®åŸºç›¤ç¢ºèªãŒå®Œäº†ã—ã¾ã—ãŸï¼**

**ç¢ºèªã—ãŸå†…å®¹:**
- æ—¢å­˜ãƒ†ãƒ¼ãƒ–ãƒ«ã®çŠ¶æ³ç¢ºèª
- `SPLIT_TEXT_RECURSIVE_CHARACTER`: ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²
- `TRANSLATE`: å¤šè¨€èªç¿»è¨³
- `SENTIMENT`: æ„Ÿæƒ…åˆ†æ
- `EMBED_TEXT_1024`: ãƒ™ã‚¯ãƒˆãƒ«åŸ‹ã‚è¾¼ã¿

**ç¢ºèªã—ãŸãƒ†ãƒ¼ãƒ–ãƒ«:**
- RETAIL_DATA_WITH_PRODUCT_MASTER: åº—èˆ—ãƒ‡ãƒ¼ã‚¿
- EC_DATA_WITH_PRODUCT_MASTER: ECãƒ‡ãƒ¼ã‚¿
- CUSTOMER_REVIEWS: é¡§å®¢ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿
- SNOW_RETAIL_DOCUMENTS: ç¤¾å†…ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
""")

st.info("ğŸ’¡ **æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—**: Step2ã§ã¯ã€AI_CLASSIFYã€AI_FILTERã€AI_AGGãªã©ã®AIé–¢æ•°ã‚’ä½¿ã£ãŸé«˜åº¦ãªåˆ†æã‚’å­¦ç¿’ã—ã¾ã™ã€‚")

st.markdown("---")
st.markdown(f"**Snowflake Cortex Handson ã‚·ãƒŠãƒªã‚ª#2 | Step1: ãƒ‡ãƒ¼ã‚¿æº–å‚™**") 
